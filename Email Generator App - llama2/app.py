import streamlit as st
from langchain.prompts import PromptTemplate
# Recently the below import has been replaced by later one
# from langchain.llms import CTransformers
from langchain_community.llms import CTransformers

#Function to get the response back
def getLLMResponse(form_input,email_sender,email_recipient,email_style):
    # ä½¿ç”¨OpenAIä¸¦è¨­å®šæº«åº¦ç‚º0.9ï¼Œæ¨¡å‹ç‚º"text-davinci-003"

    # ç‚ºLlama-2-7B-Chatçš„åŒ…è£å™¨ï¼Œé‹è¡ŒLlama 2æ–¼CPUä¸Š

    # é‡åŒ–æ˜¯é€šéå°‡æ¬Šé‡å¾16ä½æµ®é»æ•¸è½‰æ›æˆ8ä½æ•´æ•¸ä¾†é™ä½æ¨¡å‹ç²¾åº¦ï¼Œ
    # ä½¿å…¶èƒ½å¤ åœ¨è³‡æºæœ‰é™çš„è¨­å‚™ä¸Šæœ‰æ•ˆéƒ¨ç½²ï¼Œæ¸›å°‘æ¨¡å‹å¤§å°ï¼ŒåŒæ™‚ä¿æŒæ€§èƒ½ã€‚

    # C Transformersæ”¯æŒå„ç¨®é–‹æºæ¨¡å‹ï¼Œ
    # å…¶ä¸­åŒ…æ‹¬åƒæ˜¯Llamaã€GPT4All-Jã€MPTå’ŒFalconç­‰å—æ­¡è¿çš„æ¨¡å‹ã€‚


    # C Transformersæ˜¯ä¸€å€‹Pythonåº«ï¼Œå®ƒç‚ºä½¿ç”¨GGMLåº«ç”¨C/C++å¯¦ç¾çš„è®Šæ›å™¨æ¨¡å‹æä¾›äº†ç¶å®š


    llm = CTransformers(model='D:/readingtask_GPT/Langchain/llama2/models/llama-2-7b-chat.ggmlv3.q8_0.bin',     #https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main
                    model_type='llama',
                    config={'max_new_tokens': 256,
                            'temperature': 0.01})
    
    
    #Template for building the PROMPT
    template = """
    Write a email with {style} style and includes topic :{email_topic}.\n\nSender: {sender}\nRecipient: {recipient}
    \n\nEmail Text:
    
    """

    #Creating the final PROMPT
    prompt = PromptTemplate(
        input_variables=["style","email_topic","sender","recipient"],
        template=template,)

  
    #Generating the response using LLM
    #langchain has recommended to use 'invoke' function for the below please :)
    response=llm.invoke(prompt.format(email_topic=form_input,sender=email_sender,recipient=email_recipient,style=email_style))
    print(response)

    return response

#################### streamlitå‰ç«¯è¨­å®š #################################

st.set_page_config( page_title="Generate Emails",
                    page_icon='ğŸ“§',
                    layout='centered',
                    initial_sidebar_state='collapsed')

st.header("Generate Emails ğŸ“§")

form_input = st.text_area('Enter the email topic', height=275)

#Creating columns for the UI - To receive inputs from user
col1, col2, col3 = st.columns([10, 10, 5])
with col1:
    email_sender = st.text_input('å¯„ä¿¡è€…')
with col2:
    email_recipient = st.text_input('æ¥æ”¶è€…')
with col3:
    email_style = st.selectbox('å¯«ä½œé¢¨æ ¼',
                                    ('Formal', 'Appreciating', 'Not Satisfied', 'Neutral'),
                                       index=0)


submit = st.button("ç”¢ç”Ÿ!!")

#When 'Generate' button is clicked, execute the below code
if submit:
    st.write(getLLMResponse(form_input,email_sender,email_recipient,email_style))
